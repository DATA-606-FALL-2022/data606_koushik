{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data Exploration"
      ],
      "metadata": {
        "id": "n21xqHfm4fxQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Dt4dgknoWnL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import *\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data"
      ],
      "metadata": {
        "id": "mDfKhj9d8mCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading all the images into a numpy array\n",
        "images = []\n",
        "for file in os.listdir():\n",
        "  if file.endswith('.jpg'):\n",
        "    #if the file is an image\n",
        "    image_values = cv2.imread(file)\n",
        "\n",
        "    #resize the image into 360 x 480 pixels\n",
        "    image_values = cv2.resize(image_values,(360,480))\n",
        "\n",
        "    images.append(image_values)\n",
        "\n",
        "#storing everything in a numpy array\n",
        "images_array = np.array(images)"
      ],
      "metadata": {
        "id": "GDIySlf_4mp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding number of observations"
      ],
      "metadata": {
        "id": "FtWepnOn8n-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_observations = len(images_array)\n",
        "number_of_observations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDxkKLpo8WNG",
        "outputId": "e7b5668f-6342-4fa9-e29b-2f9987f942a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we are working on a image dataset we do not have any columns "
      ],
      "metadata": {
        "id": "nDGS2zhG8rXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analzing how images are stored in python variables"
      ],
      "metadata": {
        "id": "_grOvEeE60J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_array"
      ],
      "metadata": {
        "id": "ssGbDf8o41_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694e1a62-0d3c-492f-d4af-d27162bbd381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[108, 156, 228],\n",
              "         [108, 157, 229],\n",
              "         [109, 158, 230],\n",
              "         ...,\n",
              "         [ 54,  70,  77],\n",
              "         [ 54,  70,  77],\n",
              "         [ 54,  70,  77]],\n",
              "\n",
              "        [[108, 156, 228],\n",
              "         [108, 157, 229],\n",
              "         [109, 158, 230],\n",
              "         ...,\n",
              "         [ 54,  70,  77],\n",
              "         [ 54,  70,  77],\n",
              "         [ 54,  70,  77]],\n",
              "\n",
              "        [[108, 156, 228],\n",
              "         [108, 157, 229],\n",
              "         [109, 158, 230],\n",
              "         ...,\n",
              "         [ 54,  70,  77],\n",
              "         [ 54,  70,  77],\n",
              "         [ 54,  70,  77]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 54,  93, 162],\n",
              "         [ 54,  93, 162],\n",
              "         [ 55,  94, 163],\n",
              "         ...,\n",
              "         [ 19,  29,  32],\n",
              "         [ 18,  30,  32],\n",
              "         [ 18,  30,  32]],\n",
              "\n",
              "        [[ 54,  93, 162],\n",
              "         [ 54,  93, 162],\n",
              "         [ 55,  94, 163],\n",
              "         ...,\n",
              "         [ 19,  29,  32],\n",
              "         [ 18,  30,  32],\n",
              "         [ 18,  30,  32]],\n",
              "\n",
              "        [[ 54,  93, 162],\n",
              "         [ 54,  93, 162],\n",
              "         [ 55,  94, 163],\n",
              "         ...,\n",
              "         [ 19,  29,  32],\n",
              "         [ 18,  30,  32],\n",
              "         [ 18,  30,  32]]],\n",
              "\n",
              "\n",
              "       [[[226, 206, 171],\n",
              "         [226, 206, 171],\n",
              "         [226, 206, 171],\n",
              "         ...,\n",
              "         [212, 192, 145],\n",
              "         [212, 192, 145],\n",
              "         [212, 192, 145]],\n",
              "\n",
              "        [[226, 206, 171],\n",
              "         [226, 206, 171],\n",
              "         [226, 206, 171],\n",
              "         ...,\n",
              "         [212, 192, 145],\n",
              "         [212, 192, 145],\n",
              "         [212, 192, 145]],\n",
              "\n",
              "        [[226, 206, 171],\n",
              "         [226, 206, 171],\n",
              "         [226, 206, 171],\n",
              "         ...,\n",
              "         [212, 192, 145],\n",
              "         [212, 192, 145],\n",
              "         [212, 192, 145]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[217, 205, 171],\n",
              "         [217, 205, 171],\n",
              "         [217, 205, 171],\n",
              "         ...,\n",
              "         [ 66, 198, 252],\n",
              "         [ 67, 197, 252],\n",
              "         [ 68, 197, 253]],\n",
              "\n",
              "        [[217, 205, 171],\n",
              "         [217, 205, 171],\n",
              "         [217, 205, 171],\n",
              "         ...,\n",
              "         [ 66, 198, 252],\n",
              "         [ 67, 197, 253],\n",
              "         [ 68, 197, 253]],\n",
              "\n",
              "        [[217, 205, 171],\n",
              "         [217, 205, 171],\n",
              "         [217, 205, 171],\n",
              "         ...,\n",
              "         [ 66, 198, 252],\n",
              "         [ 67, 197, 253],\n",
              "         [ 68, 197, 254]]],\n",
              "\n",
              "\n",
              "       [[[226, 206, 171],\n",
              "         [226, 206, 171],\n",
              "         [226, 206, 171],\n",
              "         ...,\n",
              "         [212, 192, 145],\n",
              "         [212, 192, 145],\n",
              "         [212, 192, 145]],\n",
              "\n",
              "        [[226, 206, 171],\n",
              "         [226, 206, 171],\n",
              "         [226, 206, 171],\n",
              "         ...,\n",
              "         [212, 192, 145],\n",
              "         [212, 192, 145],\n",
              "         [212, 192, 145]],\n",
              "\n",
              "        [[226, 206, 171],\n",
              "         [226, 206, 171],\n",
              "         [226, 206, 171],\n",
              "         ...,\n",
              "         [212, 192, 145],\n",
              "         [212, 192, 145],\n",
              "         [212, 192, 145]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[217, 205, 171],\n",
              "         [217, 205, 171],\n",
              "         [217, 205, 171],\n",
              "         ...,\n",
              "         [ 66, 198, 252],\n",
              "         [ 67, 197, 252],\n",
              "         [ 68, 197, 253]],\n",
              "\n",
              "        [[217, 205, 171],\n",
              "         [217, 205, 171],\n",
              "         [217, 205, 171],\n",
              "         ...,\n",
              "         [ 66, 198, 252],\n",
              "         [ 67, 197, 253],\n",
              "         [ 68, 197, 253]],\n",
              "\n",
              "        [[217, 205, 171],\n",
              "         [217, 205, 171],\n",
              "         [217, 205, 171],\n",
              "         ...,\n",
              "         [ 66, 198, 252],\n",
              "         [ 67, 197, 253],\n",
              "         [ 68, 197, 254]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[150,  84,  79],\n",
              "         [152,  86,  81],\n",
              "         [157,  91,  84],\n",
              "         ...,\n",
              "         [188, 126, 162],\n",
              "         [188, 125, 163],\n",
              "         [188, 125, 164]],\n",
              "\n",
              "        [[150,  84,  79],\n",
              "         [152,  86,  81],\n",
              "         [157,  91,  84],\n",
              "         ...,\n",
              "         [188, 126, 162],\n",
              "         [188, 125, 163],\n",
              "         [188, 125, 164]],\n",
              "\n",
              "        [[150,  83,  80],\n",
              "         [152,  86,  81],\n",
              "         [156,  91,  85],\n",
              "         ...,\n",
              "         [188, 126, 162],\n",
              "         [188, 125, 163],\n",
              "         [188, 125, 164]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 39,  41,  49],\n",
              "         [ 60,  61,  69],\n",
              "         [102, 103, 109],\n",
              "         ...,\n",
              "         [ 93,  39,  13],\n",
              "         [ 93,  39,  14],\n",
              "         [ 93,  39,  14]],\n",
              "\n",
              "        [[ 65,  65,  74],\n",
              "         [ 90,  90,  98],\n",
              "         [141, 140, 147],\n",
              "         ...,\n",
              "         [ 88,  33,   7],\n",
              "         [ 88,  33,   7],\n",
              "         [ 88,  33,   7]],\n",
              "\n",
              "        [[ 76,  75,  84],\n",
              "         [103, 101, 109],\n",
              "         [157, 155, 162],\n",
              "         ...,\n",
              "         [ 86,  31,   4],\n",
              "         [ 86,  31,   4],\n",
              "         [ 86,  31,   4]]],\n",
              "\n",
              "\n",
              "       [[[203, 197, 152],\n",
              "         [203, 197, 151],\n",
              "         [203, 197, 150],\n",
              "         ...,\n",
              "         [200, 202, 142],\n",
              "         [200, 202, 142],\n",
              "         [200, 202, 142]],\n",
              "\n",
              "        [[203, 197, 152],\n",
              "         [203, 197, 151],\n",
              "         [203, 197, 151],\n",
              "         ...,\n",
              "         [200, 202, 142],\n",
              "         [200, 202, 142],\n",
              "         [200, 202, 142]],\n",
              "\n",
              "        [[203, 197, 152],\n",
              "         [203, 197, 152],\n",
              "         [203, 197, 150],\n",
              "         ...,\n",
              "         [200, 202, 142],\n",
              "         [200, 202, 142],\n",
              "         [200, 202, 142]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[201, 199, 145],\n",
              "         [201, 199, 145],\n",
              "         [202, 200, 146],\n",
              "         ...,\n",
              "         [201, 198, 146],\n",
              "         [201, 198, 146],\n",
              "         [201, 198, 146]],\n",
              "\n",
              "        [[201, 199, 145],\n",
              "         [201, 199, 145],\n",
              "         [202, 200, 146],\n",
              "         ...,\n",
              "         [201, 198, 147],\n",
              "         [201, 198, 147],\n",
              "         [201, 198, 147]],\n",
              "\n",
              "        [[201, 199, 145],\n",
              "         [201, 199, 145],\n",
              "         [202, 200, 146],\n",
              "         ...,\n",
              "         [202, 199, 148],\n",
              "         [202, 199, 148],\n",
              "         [202, 199, 148]]],\n",
              "\n",
              "\n",
              "       [[[ 57,  88,  89],\n",
              "         [ 58,  89,  90],\n",
              "         [ 60,  91,  92],\n",
              "         ...,\n",
              "         [ 41,  62,  60],\n",
              "         [ 41,  62,  60],\n",
              "         [ 41,  62,  60]],\n",
              "\n",
              "        [[ 57,  88,  89],\n",
              "         [ 58,  89,  90],\n",
              "         [ 60,  91,  92],\n",
              "         ...,\n",
              "         [ 41,  62,  60],\n",
              "         [ 41,  62,  60],\n",
              "         [ 41,  62,  60]],\n",
              "\n",
              "        [[ 57,  88,  89],\n",
              "         [ 58,  89,  90],\n",
              "         [ 59,  90,  91],\n",
              "         ...,\n",
              "         [ 41,  62,  60],\n",
              "         [ 41,  62,  60],\n",
              "         [ 41,  62,  60]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[104, 105, 101],\n",
              "         [105, 106, 102],\n",
              "         [108, 109, 105],\n",
              "         ...,\n",
              "         [ 73,  77,  75],\n",
              "         [ 75,  78,  74],\n",
              "         [ 76,  78,  74]],\n",
              "\n",
              "        [[104, 105, 101],\n",
              "         [105, 106, 102],\n",
              "         [108, 109, 105],\n",
              "         ...,\n",
              "         [ 74,  77,  75],\n",
              "         [ 76,  78,  74],\n",
              "         [ 77,  78,  74]],\n",
              "\n",
              "        [[104, 105, 101],\n",
              "         [105, 106, 102],\n",
              "         [108, 109, 105],\n",
              "         ...,\n",
              "         [ 75,  77,  75],\n",
              "         [ 76,  78,  74],\n",
              "         [ 77,  78,  74]]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape = images_array[0].shape\n",
        "shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPKaxQ4_65VN",
        "outputId": "0792a9da-60ed-43fc-8463-251793bea53a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(480, 360, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_array[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6KOs_RG7SrR",
        "outputId": "36be41ab-bf0b-4992-c469-c3bbf52289ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[108, 156, 228],\n",
              "        [108, 157, 229],\n",
              "        [109, 158, 230],\n",
              "        ...,\n",
              "        [ 54,  70,  77],\n",
              "        [ 54,  70,  77],\n",
              "        [ 54,  70,  77]],\n",
              "\n",
              "       [[108, 156, 228],\n",
              "        [108, 157, 229],\n",
              "        [109, 158, 230],\n",
              "        ...,\n",
              "        [ 54,  70,  77],\n",
              "        [ 54,  70,  77],\n",
              "        [ 54,  70,  77]],\n",
              "\n",
              "       [[108, 156, 228],\n",
              "        [108, 157, 229],\n",
              "        [109, 158, 230],\n",
              "        ...,\n",
              "        [ 54,  70,  77],\n",
              "        [ 54,  70,  77],\n",
              "        [ 54,  70,  77]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 54,  93, 162],\n",
              "        [ 54,  93, 162],\n",
              "        [ 55,  94, 163],\n",
              "        ...,\n",
              "        [ 19,  29,  32],\n",
              "        [ 18,  30,  32],\n",
              "        [ 18,  30,  32]],\n",
              "\n",
              "       [[ 54,  93, 162],\n",
              "        [ 54,  93, 162],\n",
              "        [ 55,  94, 163],\n",
              "        ...,\n",
              "        [ 19,  29,  32],\n",
              "        [ 18,  30,  32],\n",
              "        [ 18,  30,  32]],\n",
              "\n",
              "       [[ 54,  93, 162],\n",
              "        [ 54,  93, 162],\n",
              "        [ 55,  94, 163],\n",
              "        ...,\n",
              "        [ 19,  29,  32],\n",
              "        [ 18,  30,  32],\n",
              "        [ 18,  30,  32]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can observe that the images are stored pxiel wise as a 2d matrix where each element in the matrix is an array with 3 values in it. Those three values are RGB values(red green blue) of the pixel "
      ],
      "metadata": {
        "id": "kZunzWj07x6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing values"
      ],
      "metadata": {
        "id": "THvNMgjU9JoY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the pixel details in the image dataset are used as features for building our dep learning model"
      ],
      "metadata": {
        "id": "ss3_27qG870l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target column: Our model wil be creating new face images by taking inspiration from the images we feed it. We also train a discriminator which identifies whether an image is a real one or generated one"
      ],
      "metadata": {
        "id": "cZYINTxs9Sln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Steps to be performed in the project**"
      ],
      "metadata": {
        "id": "Gh3nx_fC9ssy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I will be loading the dataset into numpy arrays. \n",
        "* I will preprocess the images like fitting its resolution. \n",
        "* I will be creating a GAN model and training it with the dataset I loaded. \n",
        "* I will be training a discriminator that can filter whether an image is real or generated\n",
        "* Hyper parameter tuning will be performed\n",
        "* I will be creating new images using the generator.\n",
        "* For evaluation purpose, I will be taking a model available on internet to predict if generated image is a human face or not\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7kBr_eho9zLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator(img_shape):\n",
        "  model = Sequential([                                                      \n",
        "  Conv2D(32, kernel_size=5, strides=2, input_shape=img_shape, padding=\"same\"),                          \n",
        "  LeakyReLU(alpha=0.2),                           \n",
        "  Dropout(0.25),\n",
        "  Conv2D(64, kernel_size=5, strides=2, padding=\"same\"),                          \n",
        "  BatchNormalization(momentum=0.8),                           \n",
        "  LeakyReLU(alpha=0.2),                           \n",
        "  Dropout(0.25),\n",
        "  Conv2D(128, kernel_size=5, strides=2, padding=\"same\"),                         \n",
        "  BatchNormalization(momentum=0.8),                           \n",
        "  LeakyReLU(alpha=0.2),                           \n",
        "  Dropout(0.25),\n",
        "  Flatten(),                            \n",
        "  Dense(1),                           \n",
        "  Activation(\"sigmoid\")\n",
        "  ])\n",
        "                                                    \n",
        "  model.summary()                           \n",
        "  img = Input(shape=img_shape)                           \n",
        "  d_pred = model(img)                           \n",
        "  return Model(inputs=img, outputs=d_pred)"
      ],
      "metadata": {
        "id": "XYUXCv7XyO2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(z_dimension, channels):                           \n",
        "  model = Sequential([\n",
        "  Dense(2 * 120 * 90, input_dim=z_dimension),                           \n",
        "  LeakyReLU(alpha=0.2),                            \n",
        "  Reshape((120, 90, 2)),\n",
        "  UpSampling2D(),                          \n",
        "  Conv2D(128, kernel_size=5, padding=\"same\"),                           \n",
        "  BatchNormalization(momentum=0.8),                           \n",
        "  LeakyReLU(alpha=0.2),\n",
        "  UpSampling2D(),                           \n",
        "  Conv2D(64, kernel_size=5, padding=\"same\"),                           \n",
        "  BatchNormalization(momentum=0.8),                           \n",
        "  LeakyReLU(alpha=0.2),\n",
        "  Conv2D(channels, kernel_size=5, padding=\"same\"),                           \n",
        "  Activation(\"tanh\"),\n",
        "  ])\n",
        "  model.summary()                           \n",
        "  noise = Input(shape=(z_dimension,))                           \n",
        "  img = model(noise)                           \n",
        "  return Model(inputs=noise, outputs=img)"
      ],
      "metadata": {
        "id": "FoIb-ha85BwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load real pictures:                       \n",
        "x_train = images_array                                       \n",
        "# model parameters                       \n",
        "img_rows = shape[0]                       \n",
        "img_cols = shape[1]                       \n",
        "channels = 3                       \n",
        "img_shape = (img_rows, img_cols, channels)                       \n",
        "z_dimension = 32                       \n",
        "optimizer = Adam(0.0005, 0.5)"
      ],
      "metadata": {
        "id": "-4IlLFit7oBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = build_discriminator(img_shape)                       \n",
        "discriminator.compile(loss='binary_crossentropy',                                             \n",
        "                      optimizer=optimizer, metrics=['accuracy'])                                               \n",
        "generator = build_generator(z_dimension,channels)                                               \n",
        "z = Input(shape=(z_dimension,))                       \n",
        "img = generator(z)                       \n",
        "discriminator.trainable = False                       \n",
        "d_pred = discriminator(img)                       \n",
        "combined = Model(z, d_pred)                       \n",
        "combined.compile(loss='binary_crossentropy',optimizer=optimizer,                                        \n",
        "                 metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le-OOCUx8pxX",
        "outputId": "ee723f30-d9a5-46b9-bf54-d798a54a419f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 240, 180, 32)      2432      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 240, 180, 32)      0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 240, 180, 32)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 120, 90, 64)       51264     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 120, 90, 64)      256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 120, 90, 64)       0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 120, 90, 64)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 45, 128)       204928    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 60, 45, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 60, 45, 128)       0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 60, 45, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 345600)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 345601    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 604,993\n",
            "Trainable params: 604,609\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 21600)             712800    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 21600)             0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 120, 90, 2)        0         \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 240, 180, 2)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 240, 180, 128)     6528      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 240, 180, 128)    512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 240, 180, 128)     0         \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSampling  (None, 480, 360, 128)    0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 480, 360, 64)      204864    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 480, 360, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 480, 360, 64)      0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 480, 360, 3)       4803      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 480, 360, 3)       0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 929,763\n",
            "Trainable params: 929,379\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 30000\n",
        "batch = 64\n",
        "\n",
        "real_imgs = np.ones((batch, 1))\n",
        "fake_imgs = np.zeros((batch, 1))\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    index = np.random.randint(0, x_train.shape[0], batch)\n",
        "    images = x_train[index]\n",
        "    sample_noise = np.random.normal(0, 1, (batch, z_dimension))\n",
        "    gen_images = generator.predict(sample_noise)\n",
        "\n",
        "    fake_imgs_discriminator_loss = discriminator.train_on_batch(gen_images, fake_imgs)\n",
        "    real_imgs_discriminator_loss = discriminator.train_on_batch(images, real_imgs)\n",
        "    \n",
        "    total_discriminator_loss = np.add(real_imgs_discriminator_loss, fake_imgs_discriminator_loss)/2\n",
        "    sample_noise = np.random.normal(0, 1, (batch, z_dimension))\n",
        "    g_loss = combined.train_on_batch(sample_noise, real_imgs)\n",
        "    \n",
        "generator.save(\"generator.h5\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO7ZBeD09JwS",
        "outputId": "1e84940d-90ef-4ee7-85b9-6e1498ab7eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 100s 48s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vh3Yc19oa-vn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}